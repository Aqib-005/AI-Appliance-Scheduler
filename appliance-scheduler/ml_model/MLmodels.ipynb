{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28182,
     "status": "ok",
     "timestamp": 1746348311336,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "xuJhUSobFZJs",
    "outputId": "8afd9d49-a424-4e55-b60e-03e814a09fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Dissertation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTadTqzmMUBs"
   },
   "source": [
    "###Setup Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38063,
     "status": "ok",
     "timestamp": 1746348349433,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "TTS2G86gMNBJ",
    "outputId": "92eb9d11-0c30-4134-b50f-23da804026c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\shiha\\\\OneDrive\\\\Desktop\\\\FinalYearProject\\\\FYProject\\\\appliance-scheduler\\\\ml_model\\\\.venv\\\\Lib\\\\site-packages\\\\tensorflow\\\\include\\\\tensorflow\\\\compiler\\\\xla\\\\mlir_hlo\\\\_virtual_includes\\\\chlo_legalize_to_hlo_inc_gen\\\\chlo_legalize_to_hlo\\\\generated_chlo_legalize_to_hlo.inc'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\shiha\\OneDrive\\Desktop\\FinalYearProject\\FYProject\\appliance-scheduler\\ml_model\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bidirectional, LSTM, Dense, Dropout, Input\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\FinalYearProject\\FYProject\\appliance-scheduler\\ml_model\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install optuna lightgbm xgboost==1.7.5 pandas numpy matplotlib seaborn scikit-learn tensorflow joblib -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import joblib\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYa_vxnXMpRU"
   },
   "source": [
    "####Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1746348349452,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "GYXRAMtjMt19"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data):\n",
    "    # Normalize column\n",
    "    data.columns = data.columns.str.strip()\n",
    "    data.columns = data.columns.str.lower()\n",
    "    # Create mapping from CSV column names to standard names\n",
    "    mapping = {\n",
    "        'start date/time': 'StartDateTime',\n",
    "        'temperature': 'temperature',\n",
    "        'relative humidity': 'relative_humidity',\n",
    "        'precipitation': 'precipitation',\n",
    "        'rain': 'rain',\n",
    "        'snowfall': 'snowfall',\n",
    "        'weather code': 'weather_code',\n",
    "        'wind speed': 'wind_speed',\n",
    "        'price': 'Price',\n",
    "        'grid load': 'total_consumption',\n",
    "        'total generation': 'total_generation',\n",
    "        'day of week': 'DayOfWeek'\n",
    "    }\n",
    "    # Rename columns if present\n",
    "    new_cols = {}\n",
    "    for col in data.columns:\n",
    "        if col in mapping:\n",
    "            new_cols[col] = mapping[col]\n",
    "    data.rename(columns=new_cols, inplace=True)\n",
    "\n",
    "    # Define potential numeric columns\n",
    "    potential_numeric_cols = [\n",
    "        'Price', 'total_consumption', 'temperature', 'precipitation', 'rain',\n",
    "        'snowfall', 'wind_speed', 'relative_humidity', 'weather_code', 'total_generation'\n",
    "    ]\n",
    "    # Select only columns that exist in the dataframe\n",
    "    numeric_cols = [col for col in potential_numeric_cols if col in data.columns]\n",
    "\n",
    "    # Convert numeric columns\n",
    "    for col in numeric_cols:\n",
    "        data[col] = pd.to_numeric(\n",
    "            data[col].astype(str)\n",
    "            .str.replace(',', '')  # Remove commas\n",
    "            .str.replace(' ', '')\n",
    "            .str.replace('â€“', '-'),\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "    # Parse datetime format dd/mm/yyyy HH:MM\n",
    "    data['StartDateTime'] = pd.to_datetime(data['StartDateTime'], format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "    data = data.sort_values('StartDateTime').dropna(subset=['StartDateTime']).reset_index(drop=True)\n",
    "\n",
    "    day_map = {'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3,\n",
    "               'friday': 4, 'saturday': 5, 'sunday': 6}\n",
    "    if 'dayofweek' in data.columns:\n",
    "        data['DayOfWeek'] = data['DayOfWeek'].str.strip().str.lower().map(day_map)\n",
    "        data = data.dropna(subset=['DayOfWeek'])\n",
    "\n",
    "    # Interpolate numeric columns and fill missing values\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype in [np.float64, np.int64]:\n",
    "            data[col] = data[col].interpolate(method='linear', limit_direction='both')\n",
    "            data[col] = data[col].ffill().bfill()\n",
    "\n",
    "    print(\"NaN counts after preprocessing:\", data[numeric_cols].isna().sum())\n",
    "    return data\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name, return_metrics=False):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.clip(y_true, a_min=0.01, a_max=None))) * 100\n",
    "    smape = 100 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RÂ²: {r2:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    print(f\"SMAPE: {smape:.2f}%\")\n",
    "    if return_metrics:\n",
    "        return rmse, mae, r2, mape, smape\n",
    "\n",
    "def plot_predictions(dates, y_true, y_pred, title):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(dates, y_true, label='Actual', color='red', marker='x')\n",
    "    plt.plot(dates, y_pred, label='Predicted', color='blue', marker='o')\n",
    "    plt.xlabel('Date and Time')\n",
    "    plt.ylabel('Price [Euro/MWh]')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df['Hour'] = df['StartDateTime'].dt.hour\n",
    "    df['Day'] = df['StartDateTime'].dt.day\n",
    "    df['DayOfWeek'] = pd.to_numeric(df['DayOfWeek'], errors='coerce')\n",
    "    df['Hour'] = pd.to_numeric(df['Hour'], errors='coerce')\n",
    "    # Create cyclic features\n",
    "    df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "    df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "    # Lag features for Price\n",
    "    if 'Price' in df.columns:\n",
    "        df['Lag_Price_1h'] = df['Price'].shift(1)\n",
    "        df['Lag_Price_24h'] = df['Price'].shift(24)\n",
    "        df['Price_RollingStd24'] = df['Price'].rolling(window=24, min_periods=1).std()\n",
    "        df['Lag_Price_1h'] = df['Lag_Price_1h'].interpolate(method='linear', limit_direction='both').ffill().bfill()\n",
    "        df['Lag_Price_24h'] = df['Lag_Price_24h'].interpolate(method='linear', limit_direction='both').ffill().bfill()\n",
    "        df['Price_RollingStd24'] = df['Price_RollingStd24'].interpolate(method='linear', limit_direction='both').ffill().bfill()\n",
    "    else:\n",
    "        df['Lag_Price_1h'] = np.nan\n",
    "        df['Lag_Price_24h'] = np.nan\n",
    "        df['Price_RollingStd24'] = np.nan\n",
    "    # Rolling features\n",
    "    df['Rolling_Temp_24h'] = df['temperature'].rolling(window=24, min_periods=1).mean()\n",
    "    df['Rolling_Wind_24h'] = df['wind_speed'].rolling(window=24, min_periods=1).mean()\n",
    "    df['Rolling_Load_24h'] = df['total_consumption'].rolling(window=24, min_periods=1).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAykpQn4MxVD"
   },
   "source": [
    "####Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1746348350253,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "8czhT4uWM0gJ",
    "outputId": "3aed9240-b675-4269-d745-365765e3fc23"
   },
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv('data/merged-data.csv')\n",
    "future_data = pd.read_csv('data/future-data.csv')\n",
    "historical_data = load_and_preprocess_data(historical_data)\n",
    "future_data = load_and_preprocess_data(future_data)\n",
    "\n",
    "# Historical and future data load\n",
    "forecast_start_dt = pd.to_datetime('2025-02-10 00:00:00')\n",
    "forecast_end_dt = pd.to_datetime('2025-02-16 23:00:00')\n",
    "future_data = future_data[\n",
    "    (future_data['StartDateTime'] >= forecast_start_dt) &\n",
    "    (future_data['StartDateTime'] <= forecast_end_dt)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Engineer features on both datasets\n",
    "historical_data = engineer_features(historical_data)\n",
    "future_data = engineer_features(future_data)\n",
    "\n",
    "dates = historical_data['StartDateTime'].copy()\n",
    "print(\"Dates saved. First few entries:\\n\", dates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqdtqA6cEX1c"
   },
   "source": [
    "###Feature Selection & Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1746348351986,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "9nLAzbxPEbI6",
    "outputId": "b4fedf34-cee3-4070-abbd-e3825831440e"
   },
   "outputs": [],
   "source": [
    "target = 'Price'\n",
    "common_features = [\n",
    "    'temperature', 'precipitation',\n",
    "  'relative_humidity', 'total_consumption', 'total_generation', 'Hour',\n",
    "    'Hour_sin', 'Hour_cos',\n",
    "    'Lag_Price_1h', 'Lag_Price_24h', 'Rolling_Temp_24h',\n",
    "    'Rolling_Load_24h', 'Price_RollingStd24'\n",
    "]\n",
    "\n",
    "# Check columns\n",
    "for col in common_features + [target]:\n",
    "    if col not in historical_data.columns:\n",
    "        print(f\"Warning: Column {col} not in historical_data.\")\n",
    "    elif historical_data[col].isna().all():\n",
    "        print(f\"Warning: Column {col} is entirely NaN.\")\n",
    "    elif historical_data[col].nunique() == 1:\n",
    "        print(f\"Warning: Column {col} is constant with value {historical_data[col].iloc[0]}.\")\n",
    "\n",
    "corr_matrix = historical_data[common_features + [target]].corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Features and Target\")\n",
    "plt.show()\n",
    "\n",
    "# Feature selection\n",
    "target_corr = corr_matrix[target].drop(target)\n",
    "selected_features = target_corr[target_corr.abs() > 0.1].index.tolist()\n",
    "print(\"Features with absolute correlation > 0.1 with target:\", selected_features)\n",
    "\n",
    "def drop_highly_correlated_features(df, features, threshold=0.9):\n",
    "    corr = df[features].corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return [feature for feature in features if feature not in to_drop], to_drop\n",
    "\n",
    "selected_features, dropped_features = drop_highly_correlated_features(historical_data, selected_features, threshold=0.9)\n",
    "print(\"Selected features after dropping highly correlated ones:\", selected_features)\n",
    "print(\"Dropped features due to high inter-correlation:\", dropped_features)\n",
    "\n",
    "print(\"Final feature set for modeling:\", common_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzdWbeaBUuc0"
   },
   "source": [
    "####Split Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1746348351999,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "7ppN-JuQUtip",
    "outputId": "868748a9-b027-47c8-d338-f53a6363b655"
   },
   "outputs": [],
   "source": [
    "features_and_target = common_features + [target]\n",
    "historical_data = historical_data[features_and_target].dropna().reset_index(drop=True)\n",
    "\n",
    "# split sizes 60% train, 20% validation, 20% test\n",
    "n = len(historical_data)\n",
    "train_end = int(0.6 * n)\n",
    "val_end = int(0.8 * n)\n",
    "\n",
    "# Split the data while preserving temporal order\n",
    "train_data = historical_data.iloc[:train_end].reset_index(drop=True)\n",
    "val_data = historical_data.iloc[train_end:val_end].reset_index(drop=True)\n",
    "test_data = historical_data.iloc[val_end:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(train_data)} rows, Validation: {len(val_data)} rows, Test: {len(test_data)} rows\")\n",
    "\n",
    "print(\"Missing values in train_data:\", train_data.isna().sum().sum())\n",
    "print(\"Missing values in val_data:\", val_data.isna().sum().sum())\n",
    "print(\"Missing values in test_data:\", test_data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o_Nv8jQM81l"
   },
   "source": [
    "####XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 199947,
     "status": "ok",
     "timestamp": 1746348551943,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "8QtDEoy1M_-z",
    "outputId": "33475cef-2b81-4688-916f-d339a3ff4ea6"
   },
   "outputs": [],
   "source": [
    "train_val = pd.concat([train_data, val_data]).iloc[24:].reset_index(drop=True)\n",
    "X = train_val[common_features].copy()\n",
    "y = train_val[target].copy()\n",
    "X = X.ffill().bfill().fillna(0)\n",
    "\n",
    "# Scale features\n",
    "scaler_xgb = RobustScaler()\n",
    "X_scaled = scaler_xgb.fit_transform(X)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 0.9),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 10),\n",
    "        'random_state': 42,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_scaled):\n",
    "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(mean_squared_error(y_val, y_pred))\n",
    "    return np.mean(scores)\n",
    "\n",
    "study_xgb = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_xgb.optimize(objective_xgb, n_trials=20)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "print(\"Best parameters for XGBoost:\", best_params_xgb)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(**best_params_xgb, random_state=42)\n",
    "model_xgb.fit(X_scaled, y)\n",
    "\n",
    "# Evaluate on test set\n",
    "X_test = test_data[common_features].copy().ffill().bfill().fillna(0)\n",
    "y_test = test_data[target]\n",
    "X_test_scaled = scaler_xgb.transform(X_test)\n",
    "y_pred_xgb = model_xgb.predict(X_test_scaled)\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost (Test)\")\n",
    "\n",
    "# Define test_dates_xgb\n",
    "test_dates_xgb = dates.iloc[val_end:].reset_index(drop=True)\n",
    "\n",
    "# Plot actual vs predicted prices\n",
    "last_date_xgb = test_dates_xgb.max()\n",
    "three_months_prior_xgb = last_date_xgb - pd.DateOffset(months=3)\n",
    "start_idx_xgb = test_dates_xgb.searchsorted(three_months_prior_xgb, side='left')\n",
    "test_dates_last_3m_xgb = test_dates_xgb.iloc[start_idx_xgb:]\n",
    "y_test_last_3m_xgb = y_test.iloc[start_idx_xgb:]\n",
    "y_pred_last_3m_xgb = y_pred_xgb[start_idx_xgb:]\n",
    "plot_predictions(test_dates_last_3m_xgb, y_test_last_3m_xgb, y_pred_last_3m_xgb, \"XGBoost: Actual vs Predicted Prices (Last 3 Months of Test)\")\n",
    "\n",
    "#Download the models as it was the best performing\n",
    "joblib.dump(model_xgb, 'xgb_model.pkl')\n",
    "joblib.dump(scaler_xgb, 'scaler_xgb.pkl')\n",
    "print(\"XGBoost model and scaler saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NPyFnhrNDbL"
   },
   "source": [
    "####LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0WC3oNJmNF2l",
    "outputId": "0b82cf30-2e66-4d19-fb9d-0433a33d8fc8"
   },
   "outputs": [],
   "source": [
    "X_lstm = historical_data[common_features].iloc[24:].copy()\n",
    "y_lstm = historical_data.loc[X_lstm.index, target].copy()\n",
    "X_lstm = X_lstm.ffill().bfill().fillna(0)  # Handle missing values\n",
    "\n",
    "# Scale features with StandardScaler\n",
    "scaler_X_lstm = StandardScaler()\n",
    "X_lstm_scaled = scaler_X_lstm.fit_transform(X_lstm)\n",
    "\n",
    "scaler_y_lstm = StandardScaler()\n",
    "y_lstm_scaled = scaler_y_lstm.fit_transform(y_lstm.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Create sequences\n",
    "time_steps = 24\n",
    "def create_sequences(X, y, time_steps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_seq.append(X[i:i + time_steps])\n",
    "        y_seq.append(y[i + time_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_lstm_scaled, y_lstm_scaled, time_steps)\n",
    "mask = ~np.isnan(X_seq).any(axis=(1, 2)) & ~np.isnan(y_seq)\n",
    "X_seq = X_seq[mask]\n",
    "y_seq = y_seq[mask]\n",
    "\n",
    "# Hyperparameter tuning\n",
    "def objective_lstm(trial):\n",
    "    lstm_units_1 = trial.suggest_int('lstm_units_1', 16, 64)\n",
    "    lstm_units_2 = trial.suggest_int('lstm_units_2', 8, 32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    # Build model\n",
    "    inputs = Input(shape=(time_steps, len(common_features)))\n",
    "    x = Bidirectional(LSTM(lstm_units_1, return_sequences=True, kernel_regularizer=l2(0.01)))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units_2, return_sequences=False, kernel_regularizer=l2(0.01)))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(16, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipnorm=1.0), loss='mean_squared_error')\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6)\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_seq, y_seq,\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Return validation loss\n",
    "    return min(history.history['val_loss'])\n",
    "\n",
    "study_lstm = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_lstm.optimize(objective_lstm, n_trials=20)\n",
    "best_params_lstm = study_lstm.best_params\n",
    "print(\"Best parameters for LSTM:\", best_params_lstm)\n",
    "\n",
    "# Build final LSTM model\n",
    "def build_final_lstm_model(time_steps, n_features, params):\n",
    "    inputs = Input(shape=(time_steps, n_features))\n",
    "    x = Bidirectional(LSTM(params['lstm_units_1'], return_sequences=True, kernel_regularizer=l2(0.01)))(inputs)\n",
    "    x = Dropout(params['dropout_rate'])(x)\n",
    "    x = Bidirectional(LSTM(params['lstm_units_2'], return_sequences=False, kernel_regularizer=l2(0.01)))(x)\n",
    "    x = Dropout(params['dropout_rate'])(x)\n",
    "    x = Dense(16, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=params['learning_rate'], clipnorm=1.0), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model_lstm = build_final_lstm_model(time_steps, len(common_features), best_params_lstm)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6)\n",
    "\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_seq, y_seq,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "train_size = int(len(X_seq) * 0.8)\n",
    "X_test_lstm = X_seq[train_size:]\n",
    "y_test_lstm_scaled = y_seq[train_size:]\n",
    "y_pred_lstm_scaled = model_lstm.predict(X_test_lstm).flatten()\n",
    "y_pred_lstm = scaler_y_lstm.inverse_transform(y_pred_lstm_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_lstm = scaler_y_lstm.inverse_transform(y_test_lstm_scaled.reshape(-1, 1)).flatten()\n",
    "evaluate_model(y_test_lstm, y_pred_lstm, \"LSTM (Test)\")\n",
    "\n",
    "start_test_idx = 24 + time_steps + train_size\n",
    "end_test_idx = 24 + time_steps + len(X_seq)\n",
    "test_dates_lstm = dates.iloc[start_test_idx:end_test_idx].reset_index(drop=True)\n",
    "\n",
    "# Plot test predictions\n",
    "last_date_lstm = test_dates_lstm.max()\n",
    "three_months_prior_lstm = last_date_lstm - pd.DateOffset(months=3)\n",
    "start_idx_lstm = test_dates_lstm.searchsorted(three_months_prior_lstm, side='left')\n",
    "test_dates_last_3m_lstm = test_dates_lstm.iloc[start_idx_lstm:]\n",
    "y_test_last_3m_lstm = y_test_lstm[start_idx_lstm:]\n",
    "y_pred_last_3m_lstm = y_pred_lstm[start_idx_lstm:]\n",
    "plot_predictions(test_dates_last_3m_lstm, y_test_last_3m_lstm, y_pred_last_3m_lstm, \"LSTM: Actual vs Predicted Prices (Last 3 Months of Test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "236X_g9qNHuG"
   },
   "source": [
    "####Hybrid Model (XGB + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbCYqFd6NLJO"
   },
   "outputs": [],
   "source": [
    "X_full = historical_data[common_features].copy()\n",
    "X_full = X_full.ffill().bfill().fillna(0)\n",
    "X_full_scaled = scaler_X_lstm.transform(X_full)\n",
    "X_full_sequences = np.array([\n",
    "    X_full_scaled[i - time_steps:i]\n",
    "    for i in range(time_steps, len(X_full_scaled))\n",
    "])\n",
    "\n",
    "# Generate predictions and inverse transform to original scale\n",
    "lstm_preds_scaled = model_lstm.predict(X_full_sequences, verbose=0).flatten()\n",
    "lstm_preds = scaler_y_lstm.inverse_transform(lstm_preds_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Merge LSTM predictions back into historical data\n",
    "df_lstm = historical_data.reset_index(drop=False)\n",
    "df_lstm['global_idx'] = df_lstm.index\n",
    "df_preds = pd.DataFrame({\n",
    "    'global_idx': df_lstm.index[time_steps:],\n",
    "    'LSTM_pred': lstm_preds\n",
    "})\n",
    "\n",
    "df_merged = pd.merge(df_lstm, df_preds, on='global_idx', how='left')\n",
    "df_merged['LSTM_pred'] = df_merged['LSTM_pred'].ffill().fillna(0)\n",
    "df_merged = df_merged.dropna(subset=[target])\n",
    "\n",
    "# Create hybrid features\n",
    "hybrid_features = common_features + ['LSTM_pred']\n",
    "y_hybrid_log = np.log1p(df_merged[target].clip(lower=0.01))\n",
    "X_hybrid_full = df_merged[hybrid_features].copy()\n",
    "\n",
    "# Scale hybrid features\n",
    "scaler_hybrid = RobustScaler()\n",
    "X_hybrid_full_scaled = scaler_hybrid.fit_transform(X_hybrid_full)\n",
    "\n",
    "# Set up TimeSeriesSplit and Optuna tuning\n",
    "tscv_hybrid = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def objective_hybrid(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 20),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 20),\n",
    "        'random_state': 42,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv_hybrid.split(X_hybrid_full_scaled):\n",
    "        X_train, X_val = X_hybrid_full_scaled[train_idx], X_hybrid_full_scaled[val_idx]\n",
    "        y_train, y_val = y_hybrid_log.iloc[train_idx], y_hybrid_log.iloc[val_idx]\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        y_pred_log = model.predict(X_val)\n",
    "        scores.append(mean_squared_error(y_val, y_pred_log))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study_hybrid = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_hybrid.optimize(objective_hybrid, n_trials=10)\n",
    "best_params_hybrid = study_hybrid.best_params\n",
    "print(\"Best parameters for Hybrid Model:\", best_params_hybrid)\n",
    "\n",
    "model_hybrid = xgb.XGBRegressor(**best_params_hybrid, random_state=42)\n",
    "model_hybrid.fit(X_hybrid_full_scaled, y_hybrid_log,\n",
    "                 eval_set=[(X_hybrid_full_scaled, y_hybrid_log)],\n",
    "                 early_stopping_rounds=30, verbose=False)\n",
    "\n",
    "# Evaluate on test set\n",
    "train_idx_hyb, test_idx_hyb = list(tscv_hybrid.split(X_hybrid_full_scaled))[-1]\n",
    "X_train_hyb, X_test_hyb = X_hybrid_full_scaled[train_idx_hyb], X_hybrid_full_scaled[test_idx_hyb]\n",
    "y_train_hyb_log, y_test_hyb_log = y_hybrid_log.iloc[train_idx_hyb], y_hybrid_log.iloc[test_idx_hyb]\n",
    "\n",
    "y_pred_hyb_log = model_hybrid.predict(X_test_hyb)\n",
    "y_test_hyb = np.expm1(y_test_hyb_log)\n",
    "y_pred_hyb = np.expm1(y_pred_hyb_log)\n",
    "\n",
    "evaluate_model(y_test_hyb, y_pred_hyb, \"Hybrid (XGBoost + LSTM) (Historical)\")\n",
    "test_dates_hybrid = dates.iloc[test_idx_hyb].reset_index(drop=True)\n",
    "\n",
    "# Plot actual vs predicted prices\n",
    "last_date_hyb = test_dates_hybrid.max()\n",
    "three_months_prior_hyb = last_date_hyb - pd.DateOffset(months=3)\n",
    "start_idx_hyb = test_dates_hybrid.searchsorted(three_months_prior_hyb, side='left')\n",
    "test_dates_last_3m_hyb = test_dates_hybrid.iloc[start_idx_hyb:]\n",
    "y_test_last_3m_hyb = y_test_hyb[start_idx_hyb:]\n",
    "y_pred_last_3m_hyb = y_pred_hyb[start_idx_hyb:]\n",
    "plot_predictions(test_dates_last_3m_hyb, y_test_last_3m_hyb, y_pred_last_3m_hyb, \"Hybrid (XGBoost + LSTM): Actual vs Predicted Prices (Last 3 Months of Test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5xVKzsINNX-"
   },
   "source": [
    "####Future Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 41325,
     "status": "ok",
     "timestamp": 1743864914449,
     "user": {
      "displayName": "Aqib Shihan",
      "userId": "00587672477536448121"
     },
     "user_tz": -60
    },
    "id": "7uHbO9I-NPyM",
    "outputId": "f1378137-cc19-4661-f7ca-1b7df03471e7"
   },
   "outputs": [],
   "source": [
    "# Actual prices for testing\n",
    "actual_data = [\n",
    "    {\"start date/time\": \"2025-02-10 00:00:00\", \"actual_price\": 118.58},\n",
    "    {\"start date/time\": \"2025-02-10 01:00:00\", \"actual_price\": 111.82},\n",
    "    {\"start date/time\": \"2025-02-10 02:00:00\", \"actual_price\": 109.22},\n",
    "    {\"start date/time\": \"2025-02-10 03:00:00\", \"actual_price\": 106.29},\n",
    "    {\"start date/time\": \"2025-02-10 04:00:00\", \"actual_price\": 105.85},\n",
    "    {\"start date/time\": \"2025-02-10 05:00:00\", \"actual_price\": 112.00},\n",
    "    {\"start date/time\": \"2025-02-10 06:00:00\", \"actual_price\": 145.38},\n",
    "    {\"start date/time\": \"2025-02-10 07:00:00\", \"actual_price\": 162.02},\n",
    "    {\"start date/time\": \"2025-02-10 08:00:00\", \"actual_price\": 181.36},\n",
    "    {\"start date/time\": \"2025-02-10 09:00:00\", \"actual_price\": 163.18},\n",
    "    {\"start date/time\": \"2025-02-10 10:00:00\", \"actual_price\": 135.90},\n",
    "    {\"start date/time\": \"2025-02-10 11:00:00\", \"actual_price\": 115.28},\n",
    "    {\"start date/time\": \"2025-02-10 12:00:00\", \"actual_price\": 109.36},\n",
    "    {\"start date/time\": \"2025-02-10 13:00:00\", \"actual_price\": 109.74},\n",
    "    {\"start date/time\": \"2025-02-10 14:00:00\", \"actual_price\": 123.07},\n",
    "    {\"start date/time\": \"2025-02-10 15:00:00\", \"actual_price\": 128.54},\n",
    "    {\"start date/time\": \"2025-02-10 16:00:00\", \"actual_price\": 133.58},\n",
    "    {\"start date/time\": \"2025-02-10 17:00:00\", \"actual_price\": 133.82},\n",
    "    {\"start date/time\": \"2025-02-10 18:00:00\", \"actual_price\": 142.11},\n",
    "    {\"start date/time\": \"2025-02-10 19:00:00\", \"actual_price\": 114.85},\n",
    "    {\"start date/time\": \"2025-02-10 20:00:00\", \"actual_price\": 94.37},\n",
    "    {\"start date/time\": \"2025-02-10 21:00:00\", \"actual_price\": 91.48},\n",
    "    {\"start date/time\": \"2025-02-10 22:00:00\", \"actual_price\": 88.87},\n",
    "    {\"start date/time\": \"2025-02-10 23:00:00\", \"actual_price\": 87.38},\n",
    "    {\"start date/time\": \"2025-02-11 00:00:00\", \"actual_price\": 77.45},\n",
    "    {\"start date/time\": \"2025-02-11 01:00:00\", \"actual_price\": 71.10},\n",
    "    {\"start date/time\": \"2025-02-11 02:00:00\", \"actual_price\": 71.62},\n",
    "    {\"start date/time\": \"2025-02-11 03:00:00\", \"actual_price\": 74.89},\n",
    "    {\"start date/time\": \"2025-02-11 04:00:00\", \"actual_price\": 77.45},\n",
    "    {\"start date/time\": \"2025-02-11 05:00:00\", \"actual_price\": 87.44},\n",
    "    {\"start date/time\": \"2025-02-11 06:00:00\", \"actual_price\": 100.46},\n",
    "    {\"start date/time\": \"2025-02-11 07:00:00\", \"actual_price\": 134.93},\n",
    "    {\"start date/time\": \"2025-02-11 08:00:00\", \"actual_price\": 155.53},\n",
    "    {\"start date/time\": \"2025-02-11 09:00:00\", \"actual_price\": 141.42},\n",
    "    {\"start date/time\": \"2025-02-11 10:00:00\", \"actual_price\": 96.65},\n",
    "    {\"start date/time\": \"2025-02-11 11:00:00\", \"actual_price\": 92.78},\n",
    "    {\"start date/time\": \"2025-02-11 12:00:00\", \"actual_price\": 97.68},\n",
    "    {\"start date/time\": \"2025-02-11 13:00:00\", \"actual_price\": 111.11},\n",
    "    {\"start date/time\": \"2025-02-11 14:00:00\", \"actual_price\": 123.46},\n",
    "    {\"start date/time\": \"2025-02-11 15:00:00\", \"actual_price\": 143.69},\n",
    "    {\"start date/time\": \"2025-02-11 16:00:00\", \"actual_price\": 144.47},\n",
    "    {\"start date/time\": \"2025-02-11 17:00:00\", \"actual_price\": 159.97},\n",
    "    {\"start date/time\": \"2025-02-11 18:00:00\", \"actual_price\": 168.19},\n",
    "    {\"start date/time\": \"2025-02-11 19:00:00\", \"actual_price\": 167.45},\n",
    "    {\"start date/time\": \"2025-02-11 20:00:00\", \"actual_price\": 162.63},\n",
    "    {\"start date/time\": \"2025-02-11 21:00:00\", \"actual_price\": 148.75},\n",
    "    {\"start date/time\": \"2025-02-11 22:00:00\", \"actual_price\": 142.95},\n",
    "    {\"start date/time\": \"2025-02-11 23:00:00\", \"actual_price\": 128.24},\n",
    "    {\"start date/time\": \"2025-02-12 00:00:00\", \"actual_price\": 129.13},\n",
    "    {\"start date/time\": \"2025-02-12 01:00:00\", \"actual_price\": 127.77},\n",
    "    {\"start date/time\": \"2025-02-12 02:00:00\", \"actual_price\": 126.82},\n",
    "    {\"start date/time\": \"2025-02-12 03:00:00\", \"actual_price\": 126.59},\n",
    "    {\"start date/time\": \"2025-02-12 04:00:00\", \"actual_price\": 128.74},\n",
    "    {\"start date/time\": \"2025-02-12 05:00:00\", \"actual_price\": 131.24},\n",
    "    {\"start date/time\": \"2025-02-12 06:00:00\", \"actual_price\": 151.13},\n",
    "    {\"start date/time\": \"2025-02-12 07:00:00\", \"actual_price\": 163.64},\n",
    "    {\"start date/time\": \"2025-02-12 08:00:00\", \"actual_price\": 180.00},\n",
    "    {\"start date/time\": \"2025-02-12 09:00:00\", \"actual_price\": 174.92},\n",
    "    {\"start date/time\": \"2025-02-12 10:00:00\", \"actual_price\": 162.05},\n",
    "    {\"start date/time\": \"2025-02-12 11:00:00\", \"actual_price\": 144.01},\n",
    "    {\"start date/time\": \"2025-02-12 12:00:00\", \"actual_price\": 137.28},\n",
    "    {\"start date/time\": \"2025-02-12 13:00:00\", \"actual_price\": 142.03},\n",
    "    {\"start date/time\": \"2025-02-12 14:00:00\", \"actual_price\": 149.40},\n",
    "    {\"start date/time\": \"2025-02-12 15:00:00\", \"actual_price\": 159.67},\n",
    "    {\"start date/time\": \"2025-02-12 16:00:00\", \"actual_price\": 173.21},\n",
    "    {\"start date/time\": \"2025-02-12 17:00:00\", \"actual_price\": 184.59},\n",
    "    {\"start date/time\": \"2025-02-12 18:00:00\", \"actual_price\": 197.13},\n",
    "    {\"start date/time\": \"2025-02-12 19:00:00\", \"actual_price\": 192.57},\n",
    "    {\"start date/time\": \"2025-02-12 20:00:00\", \"actual_price\": 173.90},\n",
    "    {\"start date/time\": \"2025-02-12 21:00:00\", \"actual_price\": 155.78},\n",
    "    {\"start date/time\": \"2025-02-12 22:00:00\", \"actual_price\": 150.38},\n",
    "    {\"start date/time\": \"2025-02-12 23:00:00\", \"actual_price\": 141.81},\n",
    "    {\"start date/time\": \"2025-02-13 00:00:00\", \"actual_price\": 140.33},\n",
    "    {\"start date/time\": \"2025-02-13 01:00:00\", \"actual_price\": 137.75},\n",
    "    {\"start date/time\": \"2025-02-13 02:00:00\", \"actual_price\": 140.79},\n",
    "    {\"start date/time\": \"2025-02-13 03:00:00\", \"actual_price\": 136.59},\n",
    "    {\"start date/time\": \"2025-02-13 04:00:00\", \"actual_price\": 140.00},\n",
    "    {\"start date/time\": \"2025-02-13 05:00:00\", \"actual_price\": 142.00},\n",
    "    {\"start date/time\": \"2025-02-13 06:00:00\", \"actual_price\": 159.99},\n",
    "    {\"start date/time\": \"2025-02-13 07:00:00\", \"actual_price\": 190.33},\n",
    "    {\"start date/time\": \"2025-02-13 08:00:00\", \"actual_price\": 222.36},\n",
    "    {\"start date/time\": \"2025-02-13 09:00:00\", \"actual_price\": 220.05},\n",
    "    {\"start date/time\": \"2025-02-13 10:00:00\", \"actual_price\": 203.89},\n",
    "    {\"start date/time\": \"2025-02-13 11:00:00\", \"actual_price\": 184.68},\n",
    "    {\"start date/time\": \"2025-02-13 12:00:00\", \"actual_price\": 174.52},\n",
    "    {\"start date/time\": \"2025-02-13 13:00:00\", \"actual_price\": 170.10},\n",
    "    {\"start date/time\": \"2025-02-13 14:00:00\", \"actual_price\": 166.70},\n",
    "    {\"start date/time\": \"2025-02-13 15:00:00\", \"actual_price\": 170.10},\n",
    "    {\"start date/time\": \"2025-02-13 16:00:00\", \"actual_price\": 182.00},\n",
    "    {\"start date/time\": \"2025-02-13 17:00:00\", \"actual_price\": 213.05},\n",
    "    {\"start date/time\": \"2025-02-13 18:00:00\", \"actual_price\": 207.17},\n",
    "    {\"start date/time\": \"2025-02-13 19:00:00\", \"actual_price\": 196.52},\n",
    "    {\"start date/time\": \"2025-02-13 20:00:00\", \"actual_price\": 177.03},\n",
    "    {\"start date/time\": \"2025-02-13 21:00:00\", \"actual_price\": 162.92},\n",
    "    {\"start date/time\": \"2025-02-13 22:00:00\", \"actual_price\": 153.12},\n",
    "    {\"start date/time\": \"2025-02-13 23:00:00\", \"actual_price\": 138.97},\n",
    "    {\"start date/time\": \"2025-02-14 00:00:00\", \"actual_price\": 139.21},\n",
    "    {\"start date/time\": \"2025-02-14 01:00:00\", \"actual_price\": 132.80},\n",
    "    {\"start date/time\": \"2025-02-14 02:00:00\", \"actual_price\": 128.50},\n",
    "    {\"start date/time\": \"2025-02-14 03:00:00\", \"actual_price\": 127.65},\n",
    "    {\"start date/time\": \"2025-02-14 04:00:00\", \"actual_price\": 129.58},\n",
    "    {\"start date/time\": \"2025-02-14 05:00:00\", \"actual_price\": 139.59},\n",
    "    {\"start date/time\": \"2025-02-14 06:00:00\", \"actual_price\": 162.89},\n",
    "    {\"start date/time\": \"2025-02-14 07:00:00\", \"actual_price\": 227.08},\n",
    "    {\"start date/time\": \"2025-02-14 08:00:00\", \"actual_price\": 265.64},\n",
    "    {\"start date/time\": \"2025-02-14 09:00:00\", \"actual_price\": 215.11},\n",
    "    {\"start date/time\": \"2025-02-14 10:00:00\", \"actual_price\": 181.03},\n",
    "    {\"start date/time\": \"2025-02-14 11:00:00\", \"actual_price\": 163.01},\n",
    "    {\"start date/time\": \"2025-02-14 12:00:00\", \"actual_price\": 149.86},\n",
    "    {\"start date/time\": \"2025-02-14 13:00:00\", \"actual_price\": 148.61},\n",
    "    {\"start date/time\": \"2025-02-14 14:00:00\", \"actual_price\": 155.80},\n",
    "    {\"start date/time\": \"2025-02-14 15:00:00\", \"actual_price\": 175.06},\n",
    "    {\"start date/time\": \"2025-02-14 16:00:00\", \"actual_price\": 200.00},\n",
    "    {\"start date/time\": \"2025-02-14 17:00:00\", \"actual_price\": 298.91},\n",
    "    {\"start date/time\": \"2025-02-14 18:00:00\", \"actual_price\": 293.06},\n",
    "    {\"start date/time\": \"2025-02-14 19:00:00\", \"actual_price\": 225.70},\n",
    "    {\"start date/time\": \"2025-02-14 20:00:00\", \"actual_price\": 183.55},\n",
    "    {\"start date/time\": \"2025-02-14 21:00:00\", \"actual_price\": 163.79},\n",
    "    {\"start date/time\": \"2025-02-14 22:00:00\", \"actual_price\": 153.00},\n",
    "    {\"start date/time\": \"2025-02-14 23:00:00\", \"actual_price\": 140.03},\n",
    "    {\"start date/time\": \"2025-02-15 00:00:00\", \"actual_price\": 135.29},\n",
    "    {\"start date/time\": \"2025-02-15 01:00:00\", \"actual_price\": 130.34},\n",
    "    {\"start date/time\": \"2025-02-15 02:00:00\", \"actual_price\": 120.00},\n",
    "    {\"start date/time\": \"2025-02-15 03:00:00\", \"actual_price\": 118.24},\n",
    "    {\"start date/time\": \"2025-02-15 04:00:00\", \"actual_price\": 118.45},\n",
    "    {\"start date/time\": \"2025-02-15 05:00:00\", \"actual_price\": 120.37},\n",
    "    {\"start date/time\": \"2025-02-15 06:00:00\", \"actual_price\": 133.74},\n",
    "    {\"start date/time\": \"2025-02-15 07:00:00\", \"actual_price\": 148.58},\n",
    "    {\"start date/time\": \"2025-02-15 08:00:00\", \"actual_price\": 150.67},\n",
    "    {\"start date/time\": \"2025-02-15 09:00:00\", \"actual_price\": 137.01},\n",
    "    {\"start date/time\": \"2025-02-15 10:00:00\", \"actual_price\": 124.59},\n",
    "    {\"start date/time\": \"2025-02-15 11:00:00\", \"actual_price\": 118.36},\n",
    "    {\"start date/time\": \"2025-02-15 12:00:00\", \"actual_price\": 112.39},\n",
    "    {\"start date/time\": \"2025-02-15 13:00:00\", \"actual_price\": 110.01},\n",
    "    {\"start date/time\": \"2025-02-15 14:00:00\", \"actual_price\": 116.15},\n",
    "    {\"start date/time\": \"2025-02-15 15:00:00\", \"actual_price\": 128.83},\n",
    "    {\"start date/time\": \"2025-02-15 16:00:00\", \"actual_price\": 145.89},\n",
    "    {\"start date/time\": \"2025-02-15 17:00:00\", \"actual_price\": 164.54},\n",
    "    {\"start date/time\": \"2025-02-15 18:00:00\", \"actual_price\": 174.70},\n",
    "    {\"start date/time\": \"2025-02-15 19:00:00\", \"actual_price\": 164.76},\n",
    "    {\"start date/time\": \"2025-02-15 20:00:00\", \"actual_price\": 149.65},\n",
    "    {\"start date/time\": \"2025-02-15 21:00:00\", \"actual_price\": 128.31},\n",
    "    {\"start date/time\": \"2025-02-15 22:00:00\", \"actual_price\": 132.37},\n",
    "    {\"start date/time\": \"2025-02-15 23:00:00\", \"actual_price\": 124.54},\n",
    "    {\"start date/time\": \"2025-02-16 00:00:00\", \"actual_price\": 134.11},\n",
    "    {\"start date/time\": \"2025-02-16 01:00:00\", \"actual_price\": 128.90},\n",
    "    {\"start date/time\": \"2025-02-16 02:00:00\", \"actual_price\": 123.57},\n",
    "    {\"start date/time\": \"2025-02-16 03:00:00\", \"actual_price\": 119.90},\n",
    "    {\"start date/time\": \"2025-02-16 04:00:00\", \"actual_price\": 119.57},\n",
    "    {\"start date/time\": \"2025-02-16 05:00:00\", \"actual_price\": 120.18},\n",
    "    {\"start date/time\": \"2025-02-16 06:00:00\", \"actual_price\": 119.92},\n",
    "    {\"start date/time\": \"2025-02-16 07:00:00\", \"actual_price\": 127.51},\n",
    "    {\"start date/time\": \"2025-02-16 08:00:00\", \"actual_price\": 129.60},\n",
    "    {\"start date/time\": \"2025-02-16 09:00:00\", \"actual_price\": 130.49},\n",
    "    {\"start date/time\": \"2025-02-16 10:00:00\", \"actual_price\": 127.70},\n",
    "    {\"start date/time\": \"2025-02-16 11:00:00\", \"actual_price\": 124.03},\n",
    "    {\"start date/time\": \"2025-02-16 12:00:00\", \"actual_price\": 124.67},\n",
    "    {\"start date/time\": \"2025-02-16 13:00:00\", \"actual_price\": 118.77},\n",
    "    {\"start date/time\": \"2025-02-16 14:00:00\", \"actual_price\": 121.02},\n",
    "    {\"start date/time\": \"2025-02-16 15:00:00\", \"actual_price\": 129.55},\n",
    "    {\"start date/time\": \"2025-02-16 16:00:00\", \"actual_price\": 137.68},\n",
    "    {\"start date/time\": \"2025-02-16 17:00:00\", \"actual_price\": 153.98},\n",
    "    {\"start date/time\": \"2025-02-16 18:00:00\", \"actual_price\": 169.98},\n",
    "    {\"start date/time\": \"2025-02-16 19:00:00\", \"actual_price\": 160.29},\n",
    "    {\"start date/time\": \"2025-02-16 20:00:00\", \"actual_price\": 153.72},\n",
    "    {\"start date/time\": \"2025-02-16 21:00:00\", \"actual_price\": 139.34},\n",
    "    {\"start date/time\": \"2025-02-16 22:00:00\", \"actual_price\": 137.62},\n",
    "    {\"start date/time\": \"2025-02-16 23:00:00\", \"actual_price\": 131.51},\n",
    "    {\"start date/time\": \"2025-02-17 00:00:00\", \"actual_price\": 128.05},\n",
    "    {\"start date/time\": \"2025-02-17 01:00:00\", \"actual_price\": 121.06},\n",
    "    {\"start date/time\": \"2025-02-17 02:00:00\", \"actual_price\": 120.34},\n",
    "    {\"start date/time\": \"2025-02-17 03:00:00\", \"actual_price\": 125.52},\n",
    "    {\"start date/time\": \"2025-02-17 04:00:00\", \"actual_price\": 128.94},\n",
    "    {\"start date/time\": \"2025-02-17 05:00:00\", \"actual_price\": 131.54},\n",
    "    {\"start date/time\": \"2025-02-17 06:00:00\", \"actual_price\": 153.16},\n",
    "    {\"start date/time\": \"2025-02-17 07:00:00\", \"actual_price\": 204.74},\n",
    "    {\"start date/time\": \"2025-02-17 08:00:00\", \"actual_price\": 209.79},\n",
    "    {\"start date/time\": \"2025-02-17 09:00:00\", \"actual_price\": 171.30},\n",
    "    {\"start date/time\": \"2025-02-17 10:00:00\", \"actual_price\": 139.67},\n",
    "    {\"start date/time\": \"2025-02-17 11:00:00\", \"actual_price\": 117.19},\n",
    "    {\"start date/time\": \"2025-02-17 12:00:00\", \"actual_price\": 109.47},\n",
    "    {\"start date/time\": \"2025-02-17 13:00:00\", \"actual_price\": 106.78},\n",
    "    {\"start date/time\": \"2025-02-17 14:00:00\", \"actual_price\": 111.89},\n",
    "    {\"start date/time\": \"2025-02-17 15:00:00\", \"actual_price\": 132.27},\n",
    "    {\"start date/time\": \"2025-02-17 16:00:00\", \"actual_price\": 158.96},\n",
    "    {\"start date/time\": \"2025-02-17 17:00:00\", \"actual_price\": 222.92},\n",
    "    {\"start date/time\": \"2025-02-17 18:00:00\", \"actual_price\": 271.00},\n",
    "    {\"start date/time\": \"2025-02-17 19:00:00\", \"actual_price\": 215.36},\n",
    "    {\"start date/time\": \"2025-02-17 20:00:00\", \"actual_price\": 177.86},\n",
    "    {\"start date/time\": \"2025-02-17 21:00:00\", \"actual_price\": 155.19},\n",
    "    {\"start date/time\": \"2025-02-17 22:00:00\", \"actual_price\": 139.39},\n",
    "    {\"start date/time\": \"2025-02-17 23:00:00\", \"actual_price\": 129.57},\n",
    "    {\"start date/time\": \"2025-02-18 00:00:00\", \"actual_price\": 132.95},\n",
    "    {\"start date/time\": \"2025-02-18 01:00:00\", \"actual_price\": 125.00},\n",
    "    {\"start date/time\": \"2025-02-18 02:00:00\", \"actual_price\": 123.56},\n",
    "    {\"start date/time\": \"2025-02-18 03:00:00\", \"actual_price\": 117.11},\n",
    "    {\"start date/time\": \"2025-02-18 04:00:00\", \"actual_price\": 115.66},\n",
    "    {\"start date/time\": \"2025-02-18 05:00:00\", \"actual_price\": 121.93},\n",
    "    {\"start date/time\": \"2025-02-18 06:00:00\", \"actual_price\": 143.61},\n",
    "    {\"start date/time\": \"2025-02-18 07:00:00\", \"actual_price\": 190.34},\n",
    "    {\"start date/time\": \"2025-02-18 08:00:00\", \"actual_price\": 193.80},\n",
    "    {\"start date/time\": \"2025-02-18 09:00:00\", \"actual_price\": 143.53},\n",
    "    {\"start date/time\": \"2025-02-18 10:00:00\", \"actual_price\": 124.24},\n",
    "    {\"start date/time\": \"2025-02-18 11:00:00\", \"actual_price\": 109.71},\n",
    "    {\"start date/time\": \"2025-02-18 12:00:00\", \"actual_price\": 96.41},\n",
    "    {\"start date/time\": \"2025-02-18 13:00:00\", \"actual_price\": 88.53},\n",
    "    {\"start date/time\": \"2025-02-18 14:00:00\", \"actual_price\": 98.35},\n",
    "    {\"start date/time\": \"2025-02-18 15:00:00\", \"actual_price\": 110.00},\n",
    "    {\"start date/time\": \"2025-02-18 16:00:00\", \"actual_price\": 128.16},\n",
    "    {\"start date/time\": \"2025-02-18 17:00:00\", \"actual_price\": 177.61},\n",
    "    {\"start date/time\": \"2025-02-18 18:00:00\", \"actual_price\": 174.32},\n",
    "    {\"start date/time\": \"2025-02-18 19:00:00\", \"actual_price\": 155.91},\n",
    "    {\"start date/time\": \"2025-02-18 20:00:00\", \"actual_price\": 142.42},\n",
    "    {\"start date/time\": \"2025-02-18 21:00:00\", \"actual_price\": 129.41},\n",
    "    {\"start date/time\": \"2025-02-18 22:00:00\", \"actual_price\": 121.90},\n",
    "    {\"start date/time\": \"2025-02-18 23:00:00\", \"actual_price\": 114.45},\n",
    "    {\"start date/time\": \"2025-02-19 00:00:00\", \"actual_price\": 104.54},\n",
    "    {\"start date/time\": \"2025-02-19 01:00:00\", \"actual_price\": 99.29},\n",
    "    {\"start date/time\": \"2025-02-19 02:00:00\", \"actual_price\": 99.60},\n",
    "    {\"start date/time\": \"2025-02-19 03:00:00\", \"actual_price\": 97.29},\n",
    "    {\"start date/time\": \"2025-02-19 04:00:00\", \"actual_price\": 94.50},\n",
    "    {\"start date/time\": \"2025-02-19 05:00:00\", \"actual_price\": 97.48},\n",
    "    {\"start date/time\": \"2025-02-19 06:00:00\", \"actual_price\": 115.00},\n",
    "    {\"start date/time\": \"2025-02-19 07:00:00\", \"actual_price\": 149.50},\n",
    "    {\"start date/time\": \"2025-02-19 08:00:00\", \"actual_price\": 166.37},\n",
    "    {\"start date/time\": \"2025-02-19 09:00:00\", \"actual_price\": 128.76},\n",
    "    {\"start date/time\": \"2025-02-19 10:00:00\", \"actual_price\": 107.91},\n",
    "    {\"start date/time\": \"2025-02-19 11:00:00\", \"actual_price\": 89.28},\n",
    "    {\"start date/time\": \"2025-02-19 12:00:00\", \"actual_price\": 81.52},\n",
    "    {\"start date/time\": \"2025-02-19 13:00:00\", \"actual_price\": 82.74},\n",
    "    {\"start date/time\": \"2025-02-19 14:00:00\", \"actual_price\": 85.20},\n",
    "    {\"start date/time\": \"2025-02-19 15:00:00\", \"actual_price\": 90.63},\n",
    "    {\"start date/time\": \"2025-02-19 16:00:00\", \"actual_price\": 110.03},\n",
    "    {\"start date/time\": \"2025-02-19 17:00:00\", \"actual_price\": 131.28},\n",
    "    {\"start date/time\": \"2025-02-19 18:00:00\", \"actual_price\": 142.98},\n",
    "    {\"start date/time\": \"2025-02-19 19:00:00\", \"actual_price\": 144.42},\n",
    "    {\"start date/time\": \"2025-02-19 20:00:00\", \"actual_price\": 120.90},\n",
    "    {\"start date/time\": \"2025-02-19 21:00:00\", \"actual_price\": 113.75},\n",
    "    {\"start date/time\": \"2025-02-19 22:00:00\", \"actual_price\": 107.13},\n",
    "    {\"start date/time\": \"2025-02-19 23:00:00\", \"actual_price\": 99.81},\n",
    "    {\"start date/time\": \"2025-02-20 00:00:00\", \"actual_price\": 86.17},\n",
    "    {\"start date/time\": \"2025-02-20 01:00:00\", \"actual_price\": 85.20},\n",
    "    {\"start date/time\": \"2025-02-20 02:00:00\", \"actual_price\": 84.56},\n",
    "    {\"start date/time\": \"2025-02-20 03:00:00\", \"actual_price\": 83.64},\n",
    "    {\"start date/time\": \"2025-02-20 04:00:00\", \"actual_price\": 82.18},\n",
    "    {\"start date/time\": \"2025-02-20 05:00:00\", \"actual_price\": 83.84},\n",
    "    {\"start date/time\": \"2025-02-20 06:00:00\", \"actual_price\": 86.31},\n",
    "    {\"start date/time\": \"2025-02-20 07:00:00\", \"actual_price\": 110.41},\n",
    "    {\"start date/time\": \"2025-02-20 08:00:00\", \"actual_price\": 127.98},\n",
    "    {\"start date/time\": \"2025-02-20 09:00:00\", \"actual_price\": 105.87},\n",
    "    {\"start date/time\": \"2025-02-20 10:00:00\", \"actual_price\": 93.72},\n",
    "    {\"start date/time\": \"2025-02-20 11:00:00\", \"actual_price\": 87.23},\n",
    "    {\"start date/time\": \"2025-02-20 12:00:00\", \"actual_price\": 86.87},\n",
    "    {\"start date/time\": \"2025-02-20 13:00:00\", \"actual_price\": 84.51},\n",
    "    {\"start date/time\": \"2025-02-20 14:00:00\", \"actual_price\": 84.78},\n",
    "    {\"start date/time\": \"2025-02-20 15:00:00\", \"actual_price\": 90.05},\n",
    "    {\"start date/time\": \"2025-02-20 16:00:00\", \"actual_price\": 98.34},\n",
    "    {\"start date/time\": \"2025-02-20 17:00:00\", \"actual_price\": 110.13},\n",
    "    {\"start date/time\": \"2025-02-20 18:00:00\", \"actual_price\": 112.38},\n",
    "    {\"start date/time\": \"2025-02-20 19:00:00\", \"actual_price\": 122.45},\n",
    "    {\"start date/time\": \"2025-02-20 20:00:00\", \"actual_price\": 105.91},\n",
    "    {\"start date/time\": \"2025-02-20 21:00:00\", \"actual_price\": 92.41},\n",
    "    {\"start date/time\": \"2025-02-20 22:00:00\", \"actual_price\": 90.84},\n",
    "    {\"start date/time\": \"2025-02-20 23:00:00\", \"actual_price\": 83.00},\n",
    "    {\"start date/time\": \"2025-02-21 00:00:00\", \"actual_price\": 75.51},\n",
    "    {\"start date/time\": \"2025-02-21 01:00:00\", \"actual_price\": 74.99},\n",
    "    {\"start date/time\": \"2025-02-21 02:00:00\", \"actual_price\": 79.80},\n",
    "    {\"start date/time\": \"2025-02-21 03:00:00\", \"actual_price\": 83.40},\n",
    "    {\"start date/time\": \"2025-02-21 04:00:00\", \"actual_price\": 82.40},\n",
    "    {\"start date/time\": \"2025-02-21 05:00:00\", \"actual_price\": 82.03},\n",
    "    {\"start date/time\": \"2025-02-21 06:00:00\", \"actual_price\": 106.47},\n",
    "    {\"start date/time\": \"2025-02-21 07:00:00\", \"actual_price\": 152.50},\n",
    "    {\"start date/time\": \"2025-02-21 08:00:00\", \"actual_price\": 145.21},\n",
    "    {\"start date/time\": \"2025-02-21 09:00:00\", \"actual_price\": 120.98},\n",
    "    {\"start date/time\": \"2025-02-21 10:00:00\", \"actual_price\": 98.68},\n",
    "    {\"start date/time\": \"2025-02-21 11:00:00\", \"actual_price\": 83.40},\n",
    "    {\"start date/time\": \"2025-02-21 12:00:00\", \"actual_price\": 78.00},\n",
    "    {\"start date/time\": \"2025-02-21 13:00:00\", \"actual_price\": 76.41},\n",
    "    {\"start date/time\": \"2025-02-21 14:00:00\", \"actual_price\": 79.52},\n",
    "    {\"start date/time\": \"2025-02-21 15:00:00\", \"actual_price\": 82.94},\n",
    "    {\"start date/time\": \"2025-02-21 16:00:00\", \"actual_price\": 103.47},\n",
    "    {\"start date/time\": \"2025-02-21 17:00:00\", \"actual_price\": 103.45},\n",
    "    {\"start date/time\": \"2025-02-21 18:00:00\", \"actual_price\": 101.98},\n",
    "    {\"start date/time\": \"2025-02-21 19:00:00\", \"actual_price\": 81.95},\n",
    "    {\"start date/time\": \"2025-02-21 20:00:00\", \"actual_price\": 80.25},\n",
    "    {\"start date/time\": \"2025-02-21 21:00:00\", \"actual_price\": 70.85},\n",
    "    {\"start date/time\": \"2025-02-21 22:00:00\", \"actual_price\": 70.64},\n",
    "    {\"start date/time\": \"2025-02-21 23:00:00\", \"actual_price\": 64.33},\n",
    "    {\"start date/time\": \"2025-02-22 00:00:00\", \"actual_price\": 50.99},\n",
    "    {\"start date/time\": \"2025-02-22 01:00:00\", \"actual_price\": 48.62},\n",
    "    {\"start date/time\": \"2025-02-22 02:00:00\", \"actual_price\": 47.96},\n",
    "    {\"start date/time\": \"2025-02-22 03:00:00\", \"actual_price\": 42.62},\n",
    "    {\"start date/time\": \"2025-02-22 04:00:00\", \"actual_price\": 41.20},\n",
    "    {\"start date/time\": \"2025-02-22 05:00:00\", \"actual_price\": 49.15},\n",
    "    {\"start date/time\": \"2025-02-22 06:00:00\", \"actual_price\": 49.11},\n",
    "    {\"start date/time\": \"2025-02-22 07:00:00\", \"actual_price\": 61.22},\n",
    "    {\"start date/time\": \"2025-02-22 08:00:00\", \"actual_price\": 68.25},\n",
    "    {\"start date/time\": \"2025-02-22 09:00:00\", \"actual_price\": 67.74},\n",
    "    {\"start date/time\": \"2025-02-22 10:00:00\", \"actual_price\": 53.21},\n",
    "    {\"start date/time\": \"2025-02-22 11:00:00\", \"actual_price\": 47.13},\n",
    "    {\"start date/time\": \"2025-02-22 12:00:00\", \"actual_price\": 40.40},\n",
    "    {\"start date/time\": \"2025-02-22 13:00:00\", \"actual_price\": 52.69},\n",
    "    {\"start date/time\": \"2025-02-22 14:00:00\", \"actual_price\": 68.00},\n",
    "    {\"start date/time\": \"2025-02-22 15:00:00\", \"actual_price\": 85.60},\n",
    "    {\"start date/time\": \"2025-02-22 16:00:00\", \"actual_price\": 100.95},\n",
    "    {\"start date/time\": \"2025-02-22 17:00:00\", \"actual_price\": 108.38},\n",
    "    {\"start date/time\": \"2025-02-22 18:00:00\", \"actual_price\": 106.98},\n",
    "    {\"start date/time\": \"2025-02-22 19:00:00\", \"actual_price\": 115.18},\n",
    "    {\"start date/time\": \"2025-02-22 20:00:00\", \"actual_price\": 103.00},\n",
    "    {\"start date/time\": \"2025-02-22 21:00:00\", \"actual_price\": 101.58},\n",
    "    {\"start date/time\": \"2025-02-22 22:00:00\", \"actual_price\": 94.27},\n",
    "    {\"start date/time\": \"2025-02-22 23:00:00\", \"actual_price\": 83.51},\n",
    "    {\"start date/time\": \"2025-02-23 00:00:00\", \"actual_price\": 91.10},\n",
    "    {\"start date/time\": \"2025-02-23 01:00:00\", \"actual_price\": 84.99},\n",
    "    {\"start date/time\": \"2025-02-23 02:00:00\", \"actual_price\": 86.21},\n",
    "    {\"start date/time\": \"2025-02-23 03:00:00\", \"actual_price\": 83.63},\n",
    "    {\"start date/time\": \"2025-02-23 04:00:00\", \"actual_price\": 85.77},\n",
    "    {\"start date/time\": \"2025-02-23 05:00:00\", \"actual_price\": 87.33},\n",
    "    {\"start date/time\": \"2025-02-23 06:00:00\", \"actual_price\": 87.70},\n",
    "    {\"start date/time\": \"2025-02-23 07:00:00\", \"actual_price\": 108.00},\n",
    "    {\"start date/time\": \"2025-02-23 08:00:00\", \"actual_price\": 112.24},\n",
    "    {\"start date/time\": \"2025-02-23 09:00:00\", \"actual_price\": 99.35},\n",
    "    {\"start date/time\": \"2025-02-23 10:00:00\", \"actual_price\": 83.00},\n",
    "    {\"start date/time\": \"2025-02-23 11:00:00\", \"actual_price\": 81.50},\n",
    "    {\"start date/time\": \"2025-02-23 12:00:00\", \"actual_price\": 71.12},\n",
    "    {\"start date/time\": \"2025-02-23 13:00:00\", \"actual_price\": 69.20},\n",
    "    {\"start date/time\": \"2025-02-23 14:00:00\", \"actual_price\": 64.75},\n",
    "    {\"start date/time\": \"2025-02-23 15:00:00\", \"actual_price\": 69.11},\n",
    "    {\"start date/time\": \"2025-02-23 16:00:00\", \"actual_price\": 84.70},\n",
    "    {\"start date/time\": \"2025-02-23 17:00:00\", \"actual_price\": 150.45},\n",
    "    {\"start date/time\": \"2025-02-23 18:00:00\", \"actual_price\": 154.69},\n",
    "    {\"start date/time\": \"2025-02-23 19:00:00\", \"actual_price\": 117.02},\n",
    "    {\"start date/time\": \"2025-02-23 20:00:00\", \"actual_price\": 96.03},\n",
    "    {\"start date/time\": \"2025-02-23 21:00:00\", \"actual_price\": 77.32},\n",
    "    {\"start date/time\": \"2025-02-23 22:00:00\", \"actual_price\": 73.81},\n",
    "    {\"start date/time\": \"2025-02-23 23:00:00\", \"actual_price\": 65.99}\n",
    "]\n",
    "\n",
    "actual_df = pd.DataFrame(actual_data)\n",
    "actual_df['StartDateTime'] = pd.to_datetime(actual_df['start date/time'])\n",
    "\n",
    "# XGBoost Forecasting\n",
    "last_hist_xgb = historical_data.tail(48)\n",
    "price_history_xgb = list(last_hist_xgb['Price'])\n",
    "predictions_xgb = []\n",
    "\n",
    "for idx, row in future_data.iterrows():\n",
    "    feature_vector = []\n",
    "    for feature in common_features:\n",
    "        if feature in ['Lag_Price_1h', 'Lag_Price_24h']:\n",
    "            lag = int(feature.split('_')[-1].replace('h', ''))\n",
    "            value = predictions_xgb[-lag] if len(predictions_xgb) >= lag else price_history_xgb[-lag]\n",
    "            feature_vector.append(value)\n",
    "        elif 'Rolling' in feature or 'Std' in feature:\n",
    "            feature_vector.append(row[feature] if pd.notna(row[feature]) else last_hist_xgb[feature].mean())\n",
    "        else:\n",
    "            feature_vector.append(row[feature])\n",
    "    feature_vector_scaled = scaler_xgb.transform([feature_vector])\n",
    "    pred_price = model_xgb.predict(feature_vector_scaled)[0]\n",
    "    predictions_xgb.append(pred_price)\n",
    "    price_history_xgb.append(pred_price)\n",
    "\n",
    "future_data['Predicted Price [Euro/MWh] XGBoost'] = predictions_xgb\n",
    "\n",
    "# LSTM Forecasting\n",
    "last_hist_lstm = historical_data.tail(time_steps)\n",
    "last_hist_lstm[common_features] = last_hist_lstm[common_features].ffill().bfill()\n",
    "initial_sequence = scaler_X_lstm.transform(last_hist_lstm[common_features].values)\n",
    "price_history_lstm = list(historical_data['Price'])\n",
    "predictions_lstm = []\n",
    "\n",
    "for idx, row in future_data.iterrows():\n",
    "    features_for_pred = []\n",
    "    for feature in common_features:\n",
    "        if 'Lag_Price' in feature:\n",
    "            lag = int(feature.split('_')[-1].replace('h', ''))\n",
    "            value = (predictions_lstm[-lag] if len(predictions_lstm) >= lag and not np.isnan(predictions_lstm[-lag])\n",
    "                     else price_history_lstm[-lag])\n",
    "            features_for_pred.append(value)\n",
    "        elif 'Rolling' in feature or 'Std' in feature:\n",
    "            features_for_pred.append(row[feature] if pd.notna(row[feature]) else last_hist_lstm[feature].mean())\n",
    "        else:\n",
    "            features_for_pred.append(row[feature] if pd.notna(row[feature]) else historical_data[feature].mean())\n",
    "\n",
    "    features_for_pred = pd.Series(features_for_pred, index=common_features).fillna(historical_data[common_features].mean()).values\n",
    "    features_scaled = scaler_X_lstm.transform([features_for_pred])\n",
    "    initial_sequence = np.roll(initial_sequence, -1, axis=0)\n",
    "    initial_sequence[-1] = features_scaled[0]\n",
    "    input_seq = initial_sequence.reshape(1, time_steps, len(common_features))\n",
    "    pred_scaled = model_lstm.predict(input_seq, verbose=0).flatten()[0]\n",
    "\n",
    "    if np.isnan(pred_scaled):\n",
    "        pred_scaled = scaler_y_lstm.transform([[price_history_lstm[-1]]])[0][0]\n",
    "\n",
    "    pred_price = scaler_y_lstm.inverse_transform([[pred_scaled]])[0][0]\n",
    "    predictions_lstm.append(pred_price)\n",
    "    price_history_lstm.append(pred_price)\n",
    "\n",
    "future_data['Predicted Price [Euro/MWh] LSTM'] = predictions_lstm\n",
    "\n",
    "# Hybrid Forecasting (LSTM + XGBoost)\n",
    "last_hist_hybrid = historical_data.tail(24)\n",
    "price_history_hybrid = list(last_hist_hybrid['Price'])\n",
    "predictions_hybrid = []\n",
    "hybrid_features = common_features + ['LSTM_pred']\n",
    "\n",
    "for idx, row in future_data.iterrows():\n",
    "    new_row = pd.Series(index=hybrid_features, dtype=float)\n",
    "    for feature in common_features:\n",
    "        if feature in ['total_consumption', 'temperature', 'wind_speed', 'relative_humidity', 'Hour_sin', 'Hour_cos']:\n",
    "            new_row[feature] = row[feature]\n",
    "        elif feature == 'Lag_Price_1h':\n",
    "            new_row[feature] = predictions_hybrid[-1] if predictions_hybrid else price_history_hybrid[-1]\n",
    "        elif feature == 'Lag_Price_24h':\n",
    "            new_row[feature] = predictions_hybrid[-24] if len(predictions_hybrid) >= 24 else price_history_hybrid[-24]\n",
    "        elif 'Rolling' in feature or 'Std' in feature:\n",
    "            prices = price_history_hybrid + predictions_hybrid\n",
    "            if feature == 'Price_RollingStd24':\n",
    "                new_row[feature] = np.std(prices[-24:]) if len(prices) >= 24 else 0\n",
    "            else:\n",
    "                new_row[feature] = row[feature] if pd.notna(row[feature]) else last_hist_hybrid[feature].mean()\n",
    "    new_row['LSTM_pred'] = predictions_lstm[idx]\n",
    "    new_row = new_row.fillna(0)\n",
    "    new_row_scaled = scaler_hybrid.transform(new_row.to_frame().T)\n",
    "    pred_price_log = model_hybrid.predict(new_row_scaled)[0]\n",
    "    pred_price = np.expm1(pred_price_log)\n",
    "    predictions_hybrid.append(pred_price)\n",
    "    price_history_hybrid.append(pred_price)\n",
    "\n",
    "future_data['Predicted Price [Euro/MWh] Hybrid'] = predictions_hybrid\n",
    "\n",
    "# Model Evaluation\n",
    "evaluation_results = {}\n",
    "for model_name, pred_col in [('XGBoost', 'Predicted Price [Euro/MWh] XGBoost'),\n",
    "                             ('LSTM', 'Predicted Price [Euro/MWh] LSTM'),\n",
    "                             ('Hybrid', 'Predicted Price [Euro/MWh] Hybrid')]:\n",
    "    merged_df = pd.merge(\n",
    "        future_data[['StartDateTime', pred_col]],\n",
    "        actual_df[['StartDateTime', 'actual_price']],\n",
    "        on='StartDateTime',\n",
    "        how='inner'\n",
    "    )\n",
    "    if not merged_df.empty:\n",
    "        print(f\"\\nEvaluating {model_name} on period: {merged_df['StartDateTime'].min()} to {merged_df['StartDateTime'].max()}\")\n",
    "        plot_predictions(\n",
    "            merged_df['StartDateTime'],\n",
    "            merged_df['actual_price'],\n",
    "            merged_df[pred_col],\n",
    "            f\"{model_name}: Predicted vs Actual Prices (2025-02-10 to 2025-02-16)\"\n",
    "        )\n",
    "        metrics = evaluate_model(merged_df['actual_price'], merged_df[pred_col], f\"{model_name} (Future)\", return_metrics=True)\n",
    "        evaluation_results[model_name] = metrics\n",
    "    else:\n",
    "        print(f\"No overlapping data found for {model_name} evaluation.\")\n",
    "\n",
    "# Compare model performance\n",
    "if evaluation_results:\n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    for model_name, (rmse, mae, r2, mape, smape) in evaluation_results.items():\n",
    "        print(f\"{model_name}: RMSE={rmse:.2f}, MAE={mae:.2f}, RÂ²={r2:.3f}, MAPE={mape:.2f}%, SMAPE={smape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgzlaFloNTOb"
   },
   "source": [
    "####End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP5ToAHfXLbCINC1T54X80v",
   "collapsed_sections": [
    "JgzlaFloNTOb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
